{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifisering av landdekke\n",
    "\n",
    "Denne demoen tar for seg klassifisering av landareale ved hjelp av et CNN (convolutional neural network).\n",
    "\n",
    "Datasettet vi skal bruke er [EuroSAT](https://github.com/phelber/EuroSAT).\n",
    "\n",
    "Som består av 27000 bilder av størrelse 64x64 piksler, fra satellitten Sentinel 2.\n",
    "\n",
    "Disse bildene er delt inn i 10 klasser:\n",
    "\n",
    "![](media/eurosat.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer nødvendige pakker\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etablere et datasett\n",
    "EuroSAT ligger allerede inne i torchvision, noe som gjør at det er lett å eksperimentere med.\n",
    "For egen data er dette steget en del mer jobb, men i dette tilfellet kan vi gjøre det med noen linjer kode.\n",
    "\n",
    "Vi splitter datasettet i trenings- og test-sett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trengs noen ganger om det oppstår ssl feil\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = torchvision.datasets.EuroSAT(\"data\",transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "train,test = random_split(dataset,[int(len(dataset)*0.85),int(len(dataset)*0.15)])\n",
    "\n",
    "batch_size = 8\n",
    "trainloader = DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "testloader = DataLoader(test,batch_size=batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sette opp en modell\n",
    "\n",
    "Vi skal teste noen froskjellige utgaver.\n",
    "\n",
    "Først en veldig enkel modell vi lager selv. Så noen eksisterende modeller i kan importere med og uten pretrente vekter.\n",
    "\n",
    "For en enkel modell setter vi opp en konvolusjonsnett med 5 lag.\n",
    "\n",
    "For en ferdig modell velger vi modellen [MobileNetv3](https://arxiv.org/abs/1704.04861), som er et konvolusjonsnett for klassifisering med relativt god ytelse for ikke så mange parametere.\n",
    "Også denne er lett tilgjengelig i torchvision.\n",
    "Vi endrer på det siste laget for å endre antall klasser fra 1000 (ImageNet) til 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.fc = nn.Linear(10816,10)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.maxpool(self.conv1(x)))\n",
    "        x = self.relu(self.maxpool(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOBILENET v3\n",
    "\n",
    "# liten modell med tilfeldige vekter\n",
    "# model = torchvision.models.mobilenet_v3_small() ; list(model.children())[-1][3] = torch.nn.Linear(1024,10)\n",
    "\n",
    "# liten modell med pretrente vekter\n",
    "# model = torchvision.models.mobilenet_v3_small(weights=torchvision.models.MobileNet_V3_Small_Weights) ; list(model.children())[-1][3] = torch.nn.Linear(1024,10)\n",
    "\n",
    "# stor modell med pretrente vekter\n",
    "# model = torchvision.models.mobilenet_v3_large(weights=torchvision.models.MobileNet_V3_Large_Weights) ; list(model.children())[-1][3] = torch.nn.Linear(1280,10)\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model,(batch_size,3,64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lage noen hjelpefunksjoner\n",
    "\n",
    "#### En funksjon for å vise frem resultater frem resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"monospace\"\n",
    "plt.rcParams[\"font.size\"] = 8\n",
    "\n",
    "def view_predictions(model,dataloader_iter):\n",
    "    model.eval()\n",
    "    batch = next(dataloader_iter)\n",
    "    images,labels = batch\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            score = model(images.to(\"cuda\")).to(\"cpu\")\n",
    "        else:\n",
    "            score = model(images)\n",
    "        vals, preds = torch.max(torch.softmax(score,axis=1),axis=1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1,figsize=(10,10),dpi=150,gridspec_kw = {'hspace':0})\n",
    "    axs.imshow(torchvision.utils.make_grid(images,nrow=1).permute(2,1,0))\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    axs.set_title(f\"{'Labels:':8s} {dataset.classes[labels[0]]:20s} {dataset.classes[labels[1]]:25s} {dataset.classes[labels[2]]:25s} {dataset.classes[labels[3]]:25s} \\n\\\n",
    "{'Preds:':8s} {dataset.classes[preds[0]]:20s} {dataset.classes[preds[1]]:25s} {dataset.classes[preds[2]]:25s} {dataset.classes[preds[3]]:25s}\",loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kjør funksjonen noen ganger for å se hva den predikerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_predictions(model,iter(DataLoader(test,batch_size=4,shuffle=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste hvor god modellen er\n",
    "\n",
    "Vi lager en funksjon som tester kan kjøres på testsettet og gi ut to tall for å måle hvor god modellen er. Accuracy er et rent mål på hvor stor andel av bildene som blir riktig klassifisert git at man velger den klassen med høyest score.\n",
    "Mean average precision (mAP) er et noe mer sofistikert mål som tar i betrakning hva slags score modellen gir for de ulike klassene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "def test_accuracy(model, dataloader,batch_lim=None):\n",
    "    model.eval()\n",
    "    map = []\n",
    "    acc = []\n",
    "    count = 0\n",
    "    for batch in dataloader:\n",
    "        images,labels = batch\n",
    "        count +=1\n",
    "        if batch_lim is not None:\n",
    "            if count > batch_lim:\n",
    "                break\n",
    "        ap = []\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                score = model(images.to(\"cuda\")).to(\"cpu\")\n",
    "            else:\n",
    "                score = model(images)\n",
    "\n",
    "\n",
    "            score = torch.softmax(score,dim=1)\n",
    "            _, prediction = torch.max(score,dim=1)\n",
    "        acc.append(np.array((prediction==labels).sum()/prediction.numel()))\n",
    "        b,c = score.shape\n",
    "        for j in range(c):\n",
    "            class_label = (labels == j) * 1\n",
    "            if torch.sum(class_label) == 0:\n",
    "                continue\n",
    "            ap.append(average_precision_score(class_label.flatten().numpy(),score[:,j].flatten().numpy()))\n",
    " \n",
    "\n",
    "        map.append(np.mean(np.array(ap)))\n",
    "\n",
    "    return np.mean(map), np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(model,testloader,batch_lim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening av modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "lossfunc = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-4)\n",
    "run = \"runs/eurosat/SimpleCNN/\"\n",
    "writer = SummaryWriter(log_dir=run)\n",
    "epochs = 5\n",
    "running_loss = []\n",
    "best = 0.3\n",
    "for e in range(epochs):\n",
    "    for i,batch in enumerate(trainloader):\n",
    "        images,labels=batch\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            labels.to(\"cuda\")\n",
    "            score = model(images.to(\"cuda\")).to(\"cpu\")\n",
    "        else:\n",
    "            score = model(images)\n",
    "\n",
    "\n",
    "        loss = lossfunc(score,labels)\n",
    "        running_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i == 0 or i % 500 == 499:\n",
    "            m_loss = np.mean(running_loss)\n",
    "            writer.add_scalar(\"loss\",m_loss,e*len(trainloader) + i)\n",
    "            map,acc = test_accuracy(model,testloader,batch_lim=500)\n",
    "            writer.add_scalar(\"val/acc\",acc,e*len(trainloader) + i)\n",
    "            writer.add_scalar(\"val/mAP\",map,e*len(trainloader) + i)\n",
    "            print(f\"E {e} B {i} Loss: {m_loss} mAP: {map*100:.2f}%   Acc: {acc*100:.2f}%\")\n",
    "            running_loss = []\n",
    "\n",
    "            if map > best:\n",
    "                torch.save(model.state_dict(),run+\"best.pt\")\n",
    "                best = map\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"runs/eurosat/SimpleCNN/best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "classes = dataset.classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def create_confusion_matrix(model,testloader,batch_lim=None):\n",
    "    cfms = []\n",
    "    count = 0\n",
    "    for i,batch in enumerate(testloader):\n",
    "        images, labels = batch\n",
    "        count +=1\n",
    "        if batch_lim is not None:\n",
    "            if count > batch_lim:\n",
    "                break\n",
    "        ap = []\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                score = model(images.to(\"cuda\")).to(\"cpu\")\n",
    "            else:\n",
    "                score = model(images)\n",
    "\n",
    "\n",
    "            score = torch.softmax(score,dim=1)\n",
    "            _, prediction = torch.max(score,dim=1)\n",
    "\n",
    "\n",
    "            cfm = confusion_matrix(labels.flatten().numpy(),prediction.flatten().numpy(),normalize='true',labels=list(range(len(classes))))\n",
    "            cfms.append(np.expand_dims(cfm,axis=0))\n",
    "\n",
    "        if batch_lim is not None:\n",
    "            if i >= batch_lim:\n",
    "                break\n",
    "    mean_cfm = np.mean(np.concatenate(cfms,axis=0),axis=0)\n",
    "    df = pd.DataFrame(mean_cfm,index=[i for i in classes],columns=[i for i in classes])\n",
    "    plt.figure(figsize=(15,15))\n",
    "    cfm_plot = sb.heatmap(df,annot=True,cmap='viridis').get_figure()\n",
    "    plt.savefig(run+\"cfm.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_confusion_matrix(model,testloader,batch_lim=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoMLKS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
